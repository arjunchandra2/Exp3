# Exp3
This repo contains a notebook `algorithms.ipynb` which implements the following bandit algorithms:

1. Exp3 for a two-armed adversarial bandit  
2. Exp3 for a two armed stochastic Bernoulli bandit
3. UCB for a two armed stochastic Bernoulli bandit

There are some basic imports in the first cell of `algorithms.ipynb`. After installing these libraries, you should be able to run each cell in the notebook sequentially without issues to run the simulations and reproduce the plots.
